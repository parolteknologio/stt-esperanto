{
  "nbformat": 4,
  "nbformat_minor": 5,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "Esperanto coqui transfer learning.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "FmrqV9IY38Mx"
      ],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f79d99ef"
      },
      "source": [
        "# Train a Coqui üê∏ STT model with a Common Voice Dataset ü§ñ\n",
        "\n",
        "üëã Hello and welcome\n",
        "\n",
        "This is a copy of the official colab file that regularly gets updates:\n",
        "https://github.com/coqui-ai/STT/tree/main/notebooks\n",
        "\n",
        "You have to do three things to get this code running for your project:\n",
        "\n",
        "\n",
        "*   Download the Common Voice Dataset and upload it to your Google Drive\n",
        "*   create a alphabet.txt file for your language\n",
        "* change a few of the paths to match your folder structure on Drive and your language code\n",
        "\n",
        "I used this notebook with a payed Google Drive account and Colab+, but it should work with the free version if your dataset is small enougth. Due to space limits in colab it likely won't work with CV datasets that are bigger than 150 GB when extracted and converted to wav and converting and packing the files inside of colab gets very hard with datasets that are biger than 15 GB.\n",
        "\n",
        "## transfer learning\n",
        "\n",
        "Transfer learning doku:\n",
        "https://stt.readthedocs.io/en/latest/TRANSFER_LEARNING.html?highlight=transfer#transfer-learning-new-alphabet\n",
        "\n",
        "\n"
      ],
      "id": "f79d99ef"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3yybouOs2s5n"
      },
      "source": [
        "# Basic setup"
      ],
      "id": "3yybouOs2s5n"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fa2aec78"
      },
      "source": [
        "## Install Coqui STT \n",
        "!git clone --depth 1 https://github.com/coqui-ai/STT.git\n",
        "!cd STT; pip install -U pip wheel setuptools; pip install .\n",
        "#right now coqui needs another version of tensorflow for GPU use, this may change in the future \n",
        "!pip uninstall --yes tensorflow && pip install tensorflow-gpu==1.15.4"
      ],
      "id": "fa2aec78",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5xxT47Ro29zd"
      },
      "source": [
        "# install libraries to convert mp3 to wav\n",
        "!apt-get install sox libsox-fmt-mp3"
      ],
      "id": "5xxT47Ro29zd",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "be5fe49c"
      },
      "source": [
        "## ‚úÖ Mount Google Drive and Download your alphabet.txt\n",
        "\n",
        "**First things first**: we need some data from Google Drive, GitHub or another source of your choice. \n"
      ],
      "id": "be5fe49c"
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YCMYI6Sq0xVx",
        "outputId": "55e17c72-cda9-445f-c926-420e77287347"
      },
      "source": [
        "# mount your private google drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "id": "YCMYI6Sq0xVx",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eLzRUNMc0Gzw"
      },
      "source": [
        "# create folder and download alphabet.txt\n",
        "! mkdir -p /content/eo/\n",
        "%cd /content/eo/\n",
        "! wget https://raw.githubusercontent.com/parolteknologio/stt-esperanto/master/deepspeech-coqui/alphabet.txt"
      ],
      "id": "eLzRUNMc0Gzw",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FmrqV9IY38Mx"
      },
      "source": [
        "# Convert mp3s to wav and create a tar.gz file of it\n",
        "**You only have to do this once, after that skip this step and use the tar file.** If you can do this on a local machine, I recommend not doing this on Colab and simply upload the result to google drive and skip this step.\n",
        "\n",
        "Based on https://stt.readthedocs.io/en/latest/COMMON_VOICE_DATA.html"
      ],
      "id": "FmrqV9IY38Mx"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2ZMPJZOtv0Ar"
      },
      "source": [
        "# untar the Dataset from Common Voice\n",
        "!mkdir -p /content/data\n",
        "!tar -xzvf \"/content/drive/MyDrive/Deepspeech/cv-corpus-7.0-2021-07-21-eo.tar.gz\" -C \"/content/data\"   "
      ],
      "id": "2ZMPJZOtv0Ar",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CNoyRU49TV11"
      },
      "source": [
        "#rename folder for easier paths below\n",
        "!mv /content/data/cv-corpus-7.0-2021-07-21 /content/data/cv-corpus-7"
      ],
      "id": "CNoyRU49TV11",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7UUkjwn8m0sX"
      },
      "source": [
        "# This step converts the mp3s to wav-files. The result will be around three times as big as your mp3 folder.\n",
        "!/content/STT/bin/import_cv2.py --filter_alphabet /content/eo/alphabet.txt /content/data/cv-corpus-7/eo\n"
      ],
      "id": "7UUkjwn8m0sX",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OkfXYEwnv_CM"
      },
      "source": [
        "#delete all mp3 files AFTER they got converted to wav (rm doesnt work with so many files in Colab)\n",
        "!find /content/data/cv-corpus-7/eo/clips/ -name \"*.mp3\" -delete"
      ],
      "id": "OkfXYEwnv_CM",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fnvqOghe76G6",
        "outputId": "a60fb869-9de7-4e5b-ad1a-fb5b12e2f43d"
      },
      "source": [
        "#pack WAVs and CSVs into tar.gz inside of the workspace\n",
        "!tar czf /content/data/converted-eo-corpus-7.tar.gz /content/data/cv-corpus-7/\n",
        "# if the files are too big you can divide it into chunks like this:\n",
        "#!split -b 6000M /content/data/converted-eo-corpus-7.tar.gz \"/content/data/corpus.tar.bz2.part\""
      ],
      "id": "fnvqOghe76G6",
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tar: Removing leading `/' from member names\n",
            "tar: /content/data/cv-corpus-7: Cannot stat: No such file or directory\n",
            "tar: Exiting with failure status due to previous errors\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x8FQPIic-K4M"
      },
      "source": [
        "#Delete Wav Files because the copy process needs disk space. This can also be done in the terminal during the copy process.\n",
        "!find /content/data/cv-corpus-7/eo/clips/ -name \"*.wav\" -delete"
      ],
      "id": "x8FQPIic-K4M",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "U-bbt4sKHrn4",
        "outputId": "c4e220d7-31e0-4e1e-c55e-81ca02982c04"
      },
      "source": [
        "#copy big file to Google Drive (for small files in low numbers mv also works well). \n",
        "import shutil\n",
        "shutil.move(\"/content/data/converted-eo-corpus-7.tar.gz\", \"/content/drive/MyDrive/Deepspeech/\")\n",
        "\n",
        "#in case there are splitted files:\n",
        "#!cp /content/data/* /content/drive/MyDrive/Deepspeech/stt-downloads/converted-corpus-parts"
      ],
      "id": "U-bbt4sKHrn4",
      "execution_count": null,
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'/content/drive/MyDrive/Deepspeech/converted-eo-corpus-7.tar.gz'"
            ]
          },
          "execution_count": 22,
          "metadata": {},
          "output_type": "execute_result"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "DF5Z8sp3PhQH"
      },
      "source": [
        "# if files don't appear in your Google Drive, this often helps (sync and disconnect drive)\n",
        "from google.colab import drive\n",
        "drive.flush_and_unmount()"
      ],
      "id": "DF5Z8sp3PhQH",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2MtGIUh2djiS"
      },
      "source": [
        "# Untar converted wav-files and download checkpoints\n",
        "This part uses the prepered file from above. This speeds up the process a lot, untaring is a lot quicker then converting everything every time you want to train a model"
      ],
      "id": "2MtGIUh2djiS"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZMc0VMjydptT"
      },
      "source": [
        "! mkdir -p /content/data\n",
        "#!tar -xzvf \"/content/drive/MyDrive/Deepspeech/stt-downloads/converted-eo-corpus-7.tar.gz\" -C \"/content/data\" \n",
        "#192 GB 30 min  \n",
        "# if you have a splitted archive use \n",
        "%cd /content/drive/MyDrive/Deepspeech/stt-downloads/converted-corpus-parts\n",
        "!cat corpus.tar.bz2.* | tar xvfz - -C /content/data"
      ],
      "id": "ZMc0VMjydptT",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kymRoF4_NGRF"
      },
      "source": [
        "#create folders for checkpoints and exports\n",
        "! mkdir -p /content/eo/checkpoints\n",
        "! mkdir -p /content/eo/exports"
      ],
      "id": "kymRoF4_NGRF",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nhxvflJHp9ja"
      },
      "source": [
        "#copy checkpoints\n",
        "#!cp /content/drive/MyDrive/Deepspeech/old_checkpoints/2048_transfer_learning_1-5/* /content/eo/checkpoints\n",
        "!cp /content/drive/MyDrive/Deepspeech/checkpoints/* /content/eo/checkpoints"
      ],
      "id": "nhxvflJHp9ja",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hAlAZCXueSp-"
      },
      "source": [
        "#copy scorer\n",
        "!cp /content/drive/MyDrive/Deepspeech/stt-downloads/kenlm.scorer /content/eo/"
      ],
      "id": "hAlAZCXueSp-",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d7XHS_HcF-Z-"
      },
      "source": [
        "#english checkpoints for transfer learning\n",
        "! mkdir -p /content/en/\n",
        "%cd /content/en/\n",
        "!wget https://github.com/coqui-ai/STT/releases/download/v1.0.0/coqui-stt-1.0.0-checkpoint.tar.gz\n",
        "!tar -xzvf \"coqui-stt-1.0.0-checkpoint.tar.gz\" -C \"/content/en\" "
      ],
      "id": "d7XHS_HcF-Z-",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d9dfac21"
      },
      "source": [
        "# ‚úÖ Configure & set hyperparameters\n",
        "\n",
        "Coqui STT comes with a long list of hyperparameters you can tweak. We've set default values, but you will often want to set your own. You can use `initialize_globals_from_args()` to do this. \n",
        "\n",
        "You must **always** configure the paths to your data, and you must **always** configure your alphabet. Additionally, here we show how you can specify the size of hidden layers (`n_hidden`), the number of epochs to train for (`epochs`), and to initialize a new model from scratch (`load_train=\"init\"`).\n",
        "\n",
        "https://stt.readthedocs.io/en/latest/playbook/TRAINING.html"
      ],
      "id": "d9dfac21"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d264fdec"
      },
      "source": [
        "from coqui_stt_training.util.config import initialize_globals_from_args\n",
        "#@title String fields\n",
        "initialize_globals_from_args(\n",
        "    alphabet_config_path=\"/content/eo/alphabet.txt\", #@param {type:\"string\"}\n",
        "    train_files=[\"/content/data/content/data/cv-corpus-7/eo/clips/train-all.csv\"], #@param {type:\"string\"}\n",
        "    dev_files=[\"/content/data/content/data/cv-corpus-7/eo/clips/dev.csv\"],#@param {type:\"string\"}\n",
        "    test_files=[\"/content/data/content/data/cv-corpus-7/eo/clips/test.csv\"], #@param {type:\"string\"}\n",
        "    load_train=\"best\",  #@param [\"best\", \"init\"] {allow-input: true} \n",
        "    #@markdown load_train=\"init\" for first epoch and \"best\" for any future training with snapsshotss\n",
        "    n_hidden=2048, \n",
        "    #@markdown size of the model. The default of 2048 is only usefull for thousands of hours of data or transfer learning\n",
        "    epochs=1, #@param {type:\"raw\"} # keep the epoch number small if you want to be able to save checkpoints regularily and stay inside of colab time restrictions\n",
        "    train_batch_size=4,#@param {type:\"raw\"} #a smaller batch size means more acuracy but also slower training\n",
        "    dev_batch_size=4,#@param {type:\"raw\"}\n",
        "    test_batch_size=4,#@param {type:\"raw\"}\n",
        "    export_batch_size=4,#@param {type:\"raw\"}\n",
        "    #automatic_mixed_precision=True,\n",
        "    dropout_rate=0.3, #@param {type:\"raw\"} #the default of 0.5 is not ideal for datasets with less thank 1000 hours\n",
        "    learning_rate=0.0001, #@param {type:\"raw\"} #decreased after problems with growing loss\n",
        "    checkpoint_dir=\"/content/eo/checkpoints\",#@param {type:\"string\"}\n",
        "    #load_checkpoint_dir=\"/content/en/coqui-stt-1.0.0-checkpoint\",\n",
        "    #save_checkpoint_dir=\"/content/eo/checkpoints\",\n",
        "    #drop_source_layers=1, #remove this after the first transfer learning\n",
        "    export_dir=\"/content/eo/exports\", #@param {type:\"string\"}\n",
        "    scorer_path=\"/content/eo/kenlm.scorer\",#@param {type:\"string\"}\n",
        "    load_cudnn=True\n",
        ")"
      ],
      "id": "d264fdec",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rZRL-Adwh3Ig"
      },
      "source": [
        "from coqui_stt_training.util.config import Config\n",
        "\n",
        "# Take a peek at the entire Config\n",
        "print(Config.to_json())"
      ],
      "id": "rZRL-Adwh3Ig",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SRsVAuoBh3Ij"
      },
      "source": [
        "## ‚úÖ Train a new model\n",
        "\n",
        "Let's kick off a training run üöÄüöÄüöÄ (using the configure you set above).\n",
        "\n",
        "This notebook should work on either a GPU or a CPU. However, GPU training is a lot quicker.\n",
        "\n",
        "https://stt.readthedocs.io/en/latest/TRAINING_ADVANCED.html"
      ],
      "id": "SRsVAuoBh3Ij"
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "Hz2O9Qyxh3Il",
        "scrolled": true
      },
      "source": [
        "from coqui_stt_training.train import train, early_training_checks\n",
        "from coqui_stt_training.evaluate  import test\n",
        "\n",
        "early_training_checks()\n",
        "\n",
        "train()\n",
        "!cp /content/eo/checkpoints/* /content/drive/MyDrive/Deepspeech/checkpoints/\n",
        "test()"
      ],
      "id": "Hz2O9Qyxh3Il",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9f6dc959"
      },
      "source": [
        "## ‚úÖ Test the model\n"
      ],
      "id": "9f6dc959"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dd42bc7a"
      },
      "source": [
        "from coqui_stt_training.evaluate  import test\n",
        "from coqui_stt_training.util.config import Config\n",
        "\n",
        "Config.test_files=[\"/content/data/content/data/cv-corpus-7/eo/clips/test.csv\"]\n",
        "Config.load_checkpoint_dir=\"/content/eo/checkpoints\"\n",
        "\n",
        "test()"
      ],
      "id": "dd42bc7a",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lSAJA5fAle04"
      },
      "source": [
        "# Create Production Model\n",
        "https://stt.readthedocs.io/en/latest/EXPORTING_MODELS.html\n",
        "\n",
        "n_hidden has to be identical to your definition above"
      ],
      "id": "lSAJA5fAle04"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ftjQw7j7mAEy"
      },
      "source": [
        "!python3 -m coqui_stt_training.export --n_hidden 2048 --checkpoint_dir /content/eo/checkpoints/ --export_dir /content/drive/MyDrive/Deepspeech/exports"
      ],
      "id": "ftjQw7j7mAEy",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hhEI-nWDlrDG"
      },
      "source": [
        "# export big filels to Drive"
      ],
      "id": "hhEI-nWDlrDG"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-4JRzCaaWmjD"
      },
      "source": [
        "s#copy big file to Google Drive (for small files in low numbers mv also works well). \n",
        "#If space gets low during the transfere open the terminal and use \"find /content/data/ -name \"*.wav\" -delete\"\n",
        "import shutil\n",
        "shutil.move(\"/content/eo\", \"/content/drive/MyDrive/Deepspeech/cp/\")"
      ],
      "id": "-4JRzCaaWmjD",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zPpsUw2OWq1j"
      },
      "source": [
        "# if files don't appear in your Google Drive, this often helps (sync and disconnect drive)\n",
        "from google.colab import drive\n",
        "drive.flush_and_unmount()"
      ],
      "id": "zPpsUw2OWq1j",
      "execution_count": null,
      "outputs": []
    }
  ]
}